<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="人工智能 geek 极客 阅读 电影"><title>Collaborative Evolutionary Reinforcement Learning | Light</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Collaborative Evolutionary Reinforcement Learning</h1><a id="logo" href="/.">Light</a><p class="description">在这座城，等一个人</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/message/"><i class="fa fa-comments"> 留言</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Collaborative Evolutionary Reinforcement Learning</h1><div class="post-meta">Jun 13, 2019<span> | </span><span class="category"><a href="/categories/学习笔记/">学习笔记</a></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#算法概述"><span class="toc-number">1.</span> <span class="toc-text">算法概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#算法讲解"><span class="toc-number">2.</span> <span class="toc-text">算法讲解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#TD3算法"><span class="toc-number">2.1.</span> <span class="toc-text">TD3算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CERL算法"><span class="toc-number">2.2.</span> <span class="toc-text">CERL算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#主要的几个点"><span class="toc-number">3.</span> <span class="toc-text">主要的几个点</span></a></li></ol></div></div><div class="post-content"><h2 id="算法概述"><a href="#算法概述" class="headerlink" title="算法概述"></a>算法概述</h2><p>该算法的主要思想就是使用k个actors组成一个population，这些actors的作用就是得到好的transactions，Learners使用这些transactions来进行学习得到好的策略。其实里面的population的存在可以理解为一种off-policy的实现方式。</p>
<h2 id="算法讲解"><a href="#算法讲解" class="headerlink" title="算法讲解"></a>算法讲解</h2><h3 id="TD3算法"><a href="#TD3算法" class="headerlink" title="TD3算法"></a>TD3算法</h3><p>CERL算法的Learner使用的是TD3算法，所以我们先简单介绍一下TD3算法。TD3算法是基于AC框架的一种算法，其使用一个deterministic policy $\pi:S\rightarrow A$和两个不同的动作值函数(critic)逼近$Q:S\times A\rightarrow R_i$.actor和critic网络通过随机从Replay Buffer里面采样mini-batchl来更新参数。critic通过最小化下面的损失函数来训练：<br>$$<br>\begin{align}<br>&amp;L_i=\frac{1}{T}\sum_i(y_i-Q_i(s_i,a_i|\theta^Q))\cr<br>&amp;\text{where} \ y_i=r_i+\gamma\min_{j=1,2}Q_j’(s_{i+1},\tilde a|\theta^{Q_j’})<br>\end{align}<br>$$<br>其中的$\tilde a=\pi’(s_{i+1}|\theta^{\pi’})+\epsilon$,$clip(\epsilon\sim N(\mu,\sigma^2) -c,c)$,公式里面的$\min_{j=1,2}$指的是两个critic里面选择最小的那个。<br>actor的训练使用采样策略梯度：<br>$$<br>\triangledown_{\theta^\pi}J\sim\frac{1}{T}\sum\triangledown_aQ(s,a|\theta_a^Q)|_{s=s_i,a=a_i}\triangledown_{\theta^\pi}\pi(s|\theta^\pi)|_{s=s_i}<br>$$<br>仔细一看其实就是导数的链式法则。</p>
<h3 id="CERL算法"><a href="#CERL算法" class="headerlink" title="CERL算法"></a>CERL算法</h3><p>该算法基于off-policy，对于行为策略，该算法使用了遗传算法的population actors来生成transactions，再加上所有Learners生成的transactions组成我们的Replay Buffer。而对于遗传算法中的actors,会依据遗传算法不停地进行进化，以努力得到好的transactions供Learners进行学习，下面是主算法流程图：<br><img src="7e0907b590094c72a4462af1ebd60a98.png" alt="f1cce5834ee89c33a72affaef7f81f05.png"><br>这里的Learners使用的是TD3算法，多个Learner之间的折价损失$\gamma$不同，Learner的初始化算法如下：<br><img src="6f09df9837bd4b7ea01c37880890c723.png" alt="703ebb055789e9f0fd4f38b8feebd44a.png"><br>注意这里使用了target网络和evaluation网络的架构。Evaluate算法用于对策略的性能表现进行测试，算法伪代码如下：<br><img src="ce803f4ff1a54c58a36f2fdd33ced905.png" alt="ac580fb9b506fad967452080b3d906ff.png"><br>其中的$\pi$值得是我们需要进行evaluate的策略，$R$是Replay Buffer，noise是往动作里面增加的噪声。再下面还有进化算法的变异操作：<br><img src="7302629a0d98448a8de7b4e8365061b2.png" alt="34e93b7c82eb0d20553f01f0e433d12f.png"><br>可以发现变异操作主要还是对策略的参数增加噪声。我们经常接触的神经网络优化算法是梯度下降，也就是通过计算损失和梯度对参数进行更新，这种算法更新速度快，但是遵循梯度的更新策略容易使得训练陷入局部最优解中，而进化算法是一种启发式搜索算法，其优化过程不依赖于梯度，不会陷入局部最优解中。</p>
<h2 id="主要的几个点"><a href="#主要的几个点" class="headerlink" title="主要的几个点"></a>主要的几个点</h2><ol>
<li>何为resources redistribution？为什么resource redistribution平衡了exploration和exploitation？算法里面有一个allocation A,其保存着每个learner对应的worker分配数目，算法每次都会计算一个$U$值，然后将其进行归一化得到一个分布，然后再从这个分布里面进行采样得到新的A，这样就每次训练一次就更新一次资源分配，这样就实现了resources redistribution.在算法的一次更新里面，每一个learner启动的worker数目不是一个，而是多个并且数目就是对应的A值，这些属于同一个learner的worker使用的是相同的策略（learner的策略），这样的话如果learner的worker数目多，它探索的策略就多，这样就增加了对应的learner的探索性，而其它分配的worker数目少的learner的exploration就低，exploitation就高。</li>
<li>交叉操作是怎么回事？使用的遗传算法里面的single-point crossover方法进行的变异操作。所谓的single-point crossover方法，也就是对</li>
<li>learner和actor有什么联系和差别？该算法的总体思想是population of actors用于产生transactions，其Evaluation的目标就是为了得到参数好的transactions用于后面的learner进行学习，所以该算法的actor就是为了给learner提供transactions。</li>
</ol>
</div><div class="tags"><a href="/tags/强化学习/">强化学习</a><a href="/tags/论文阅读/">论文阅读</a></div><div class="post-nav"><a class="pre" href="/2019/06/15/python基础语法扫盲-python2-0/">python基础语法扫盲(python2.0+)</a><a class="next" href="/2019/06/01/PPO算法/">PPO算法</a></div><div id="lv-container" data-id="city" data-uid="MTAyMC80MjMxNi8xODg2Mw"><script>(function(d, s) {
   var j, e = d.getElementsByTagName(s)[0];
   if (typeof LivereTower === 'function') { return; }
   j = d.createElement(s);
   j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
   j.async = true;
   e.parentNode.insertBefore(j, e);
})(document, 'script');
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="https://lightzhan.github.io"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/写作技能/">写作技能</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/基础技能/">基础技能</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/学习笔记/">学习笔记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/知识交流/">知识交流</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程技能/">编程技能</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/强化学习/" style="font-size: 15px;">强化学习</a> <a href="/tags/论文阅读/" style="font-size: 15px;">论文阅读</a> <a href="/tags/环境配置/" style="font-size: 15px;">环境配置</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/计算机网络/" style="font-size: 15px;">计算机网络</a> <a href="/tags/技巧锦集/" style="font-size: 15px;">技巧锦集</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a> <a href="/tags/计算机/" style="font-size: 15px;">计算机</a> <a href="/tags/概率统计/" style="font-size: 15px;">概率统计</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/02/25/说明-Announcement/">说明(Announcement)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/16/NAF-将DQN用于连续任务/">NAF:将DQN用于连续任务</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/15/CTeX安装和卸载/">CTeX安装和卸载</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/05/tmux介绍和使用/">tmux介绍和使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/03/python面向对象编程/">python面向对象编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/28/ssh隧道代理/">ssh隧道代理</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/15/python基础语法扫盲-python2-0/">python基础语法扫盲(python2.0+)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/13/Collaborative-Evolutionary-Reinforcement-Learning/">Collaborative Evolutionary Reinforcement Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/01/PPO算法/">PPO算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/30/ACER算法笔记整理/">Sample Efficient Actor-Critic With Experience Replay</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/lightzhan/" title="My github" target="_blank">My github</a><ul></ul><a href="https://Mr-solution.github.io/Notes" title="Mr-solution" target="_blank">Mr-solution</a><ul></ul><a href="https://kchu.github.io/" title="飞语流年" target="_blank">飞语流年</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Light.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>